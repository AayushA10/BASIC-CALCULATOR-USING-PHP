{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AayushA10/BASIC-CALCULATOR-USING-PHP/blob/main/Homework_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECNeNZgAnF1B"
      },
      "source": [
        "# Assignment 6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NigFWrcvkfz"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", 101)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlKNC5CVW-2u"
      },
      "source": [
        "###Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KaPON2AXFij"
      },
      "source": [
        "Column | Description\n",
        ":---|:---\n",
        "`id` | Record index\n",
        "`timestamp` | Datetime (YYYY:MM:DD HH:MM:SS) when data was collected\n",
        "`country` | Current country of employment\n",
        "`employment_status` | Whether a candidate is Full time, Part time, Independent or freelancer or company owner\n",
        "`job_title` | Current job title of the candidate\n",
        "`job_years` | Total job experience (in Years)\n",
        "`is_manager` | Whether the candidate holds a managerial position or not (Yes or No)\n",
        "`hours_per_week` | No. of hours per day committed to the current job\n",
        "`telecommute_days_per_week` | No. of telecommuting days per week (working from home)\n",
        "`education` | The highest degree in education the candidate has received\n",
        "`is_education_computer_related` | Is the education related to the field of computer science (Yes or No)\n",
        "`certifications` | Does the candidate have any relevant certifications (Yes or No)\n",
        "`salary` | Monthly Salary (in US $$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cdaWna0UZQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "6810d101-0d8c-40cb-a799-acf3e23f0c9c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'employee.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ffb82f508353>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dataset is already loaded below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employee.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'employee.csv'"
          ]
        }
      ],
      "source": [
        "# Dataset is already loaded below\n",
        "data = pd.read_csv(\"employee.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWbdq93gXkXJ"
      },
      "outputs": [],
      "source": [
        "# Dimensions of training data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6vQBflFXoFV"
      },
      "outputs": [],
      "source": [
        "# Print first few rows of data\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL6xVdbbXqfn"
      },
      "outputs": [],
      "source": [
        "# drop id, timestamp and country columns\n",
        "data = data.drop(columns=['id', 'timestamp','country'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv9DHPqAXu8r"
      },
      "outputs": [],
      "source": [
        "# Explore columns\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1gJSNOwXx7W"
      },
      "outputs": [],
      "source": [
        "# replace NANs in hours_per_week with median value of the column\n",
        "data.loc[data['hours_per_week'].isna(), 'hours_per_week'] = data['hours_per_week'].median()\n",
        "data.loc[data['telecommute_days_per_week'].isna(), 'telecommute_days_per_week'] = data['telecommute_days_per_week'].median()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uG7bBueOYhUn"
      },
      "outputs": [],
      "source": [
        "#Handling null values in categorical columns\n",
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfMmarOqYlSn"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4nq6pPZYuE0"
      },
      "source": [
        "###Data Visualization :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLlD_XEzf4wN"
      },
      "source": [
        "## Feature Encoding and Normalization\n",
        "\n",
        "Before training the model, we should perform one-hot encoding for all categorical/discrete variables, normalize continuous variables and then combine all data to form the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubPm1HOaZfJu"
      },
      "outputs": [],
      "source": [
        "# create another copy of dataset and append encoded features to it\n",
        "data_train = data.copy()\n",
        "data_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK-yV-sUf8Qt"
      },
      "outputs": [],
      "source": [
        "# select categorical features\n",
        "cat_cols = [c for c in data_train.columns if data_train[c].dtype == 'object'\n",
        "            and c not in ['is_manager', 'certifications']]\n",
        "cat_data = data_train[cat_cols]\n",
        "cat_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7eaP7PSgApc"
      },
      "outputs": [],
      "source": [
        "#Encoding binary variables\n",
        "binary_cols = ['is_manager', 'certifications']\n",
        "for c in binary_cols:\n",
        "    data_train[c] = data_train[c].replace(to_replace=['Yes'], value=1)\n",
        "    data_train[c] = data_train[c].replace(to_replace=['No'], value=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSa4SpUngEg_"
      },
      "outputs": [],
      "source": [
        "final_data = pd.get_dummies(data_train, columns=cat_cols, drop_first= True,dtype=int)\n",
        "final_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bqOF2TigICx"
      },
      "outputs": [],
      "source": [
        "final_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITmxj0mQgKxz"
      },
      "outputs": [],
      "source": [
        "final_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3oRuBW4gTJv"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P74hUqfxgNnh"
      },
      "outputs": [],
      "source": [
        "y = final_data['salary']\n",
        "X = final_data.drop(columns=['salary'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "print(\"Training Set Dimensions:\", X_train.shape)\n",
        "print(\"Validation Set Dimensions:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9rhnv44gb3z"
      },
      "source": [
        "## Pre-processing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXiQUx0wWT5X"
      },
      "source": [
        "### Standardization (Z-score normalization):\n",
        "\n",
        "$$ x_{\\text{std}} = \\frac{x - \\mu}{\\sigma} $$\n",
        "\n",
        "- **Purpose:** Standardization transforms the data to have a mean of 0 and a standard deviation of 1.\n",
        "- **Properties:**\n",
        "  - Centers the data around 0.\n",
        "  - Rescales the data to have unit variance.\n",
        "  - Does not bound the data within a specific range.\n",
        "  - Preserves the shape of the distribution.\n",
        "- **Use Cases:**\n",
        "  - Algorithms that assume zero-centered data or require features to have a similar scale (e.g., gradient descent-based algorithms, support vector machines).\n",
        "  - When the distribution of the features is Gaussian-like.\n",
        "\n",
        "### Normalization (Min-Max scaling):\n",
        "\n",
        " $$ x_{\\text{norm}} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)} $$\n",
        "\n",
        "- **Purpose:** Normalization scales the data to a fixed range, typically [0, 1] or [-1, 1].\n",
        "- **Properties:**\n",
        "  - Scales the data to a specified range.\n",
        "  - Shifts the data to start at 0.\n",
        "  - Does not affect the shape of the distribution.\n",
        "  - Preserves the relative relationships between data points.\n",
        "- **Use Cases:**\n",
        "  - Neural networks, especially those with activation functions sensitive to input magnitudes (e.g., sigmoid or tanh functions).\n",
        "  - When the distribution of the features is unknown or non-Gaussian.\n",
        "\n",
        "**Choosing Between Standardization and Normalization:**\n",
        "- Use standardization when the distribution of your features is approximately Gaussian-like and you want to center the data and rescale it to have unit variance.\n",
        "- Use normalization when the scale of your features is important, or when you need to bound the features within a specific range.\n",
        "- It's often beneficial to try both preprocessing techniques and evaluate their effects on model performance to determine which one works best for your specific dataset and model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qu7qjbRJgXHu"
      },
      "outputs": [],
      "source": [
        "# select numerical features\n",
        "num_cols = ['job_years','hours_per_week','telecommute_days_per_week']\n",
        "num_cols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_bXGF1yge_M"
      },
      "outputs": [],
      "source": [
        "# Apply standard scaling on numeric data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train[num_cols])\n",
        "X_train[num_cols] = scaler.transform(X_train[num_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1uh9nMAgkle"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3INZbxvgnDL"
      },
      "outputs": [],
      "source": [
        "#Fitting a Linear Regression Model\n",
        "reg=LinearRegression()\n",
        "reg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEbjQJYth32q"
      },
      "outputs": [],
      "source": [
        "reg.coef_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6jT9Vhxh675"
      },
      "outputs": [],
      "source": [
        "reg.intercept_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9aEdX3yiFxP"
      },
      "source": [
        "Just to recall\n",
        "\n",
        "$\\hat{y} = \\alpha + \\beta_1 * X_1 + \\beta_2 * X_2 +...$\n",
        "\n",
        "Our Final model is given by -\n",
        "\n",
        "$\\hat{y} = 6145.79 + 1.887 * X_1 + 7.22 * X_2 +...$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RtdTxfXh_DD"
      },
      "outputs": [],
      "source": [
        "# Normalized MSE (Dividing by mean)\n",
        "mean_squared_error(y_train,reg.predict(X_train))/np.mean(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmrtuGyLiLXu"
      },
      "outputs": [],
      "source": [
        "# Predict on the test data\n",
        "y_pred = reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hE8AuSIhm3Ys"
      },
      "outputs": [],
      "source": [
        "#Evaluate the model on test data\n",
        "mse = mean_squared_error(y_pred, y_test)/np.mean(y_test)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9431Yjlfohd"
      },
      "source": [
        "*A lower MSE indicates that the model's predictions are closer to the actual values on average, while a higher MSE suggests larger errors between predictions and actual values.\n",
        "❗Pre-processing on Test data not done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw0hpz3_jWUF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0yAiqA5m_Jf"
      },
      "outputs": [],
      "source": [
        "#Q1. Preprocess Test data and get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm_BQptonF1H"
      },
      "outputs": [],
      "source": [
        "y_pred = reg.predict(X_test_preprocessed)\n",
        "print(\"Predictions on test data:\", y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}